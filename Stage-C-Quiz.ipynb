{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data_for_UCI_named.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"stab\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop([\"stabf\"], 1)\n",
    "y = data[\"stabf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using standard scaler to scale the features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalised_train_df = scaler.fit_transform(X_train)\n",
    "normalised_train_df = pd.DataFrame(normalised_train_df, columns=X_train.columns)\n",
    "\n",
    "normalised_test_df = scaler.transform(X_test)\n",
    "normalised_test_df = pd.DataFrame(normalised_test_df, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14\n",
    "### What is the accuracy on the test set using the random forest classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state = 1)\n",
    "rfc.fit(normalised_train_df, y_train)\n",
    "rfc_pred = rfc.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9191    0.8778    0.8980       712\n",
      "    unstable     0.9341    0.9573    0.9456      1288\n",
      "\n",
      "    accuracy                         0.9290      2000\n",
      "   macro avg     0.9266    0.9176    0.9218      2000\n",
      "weighted avg     0.9288    0.9290    0.9286      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report is used to get all the metrics in a table\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, rfc_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929\n"
     ]
    }
   ],
   "source": [
    "# or we could import accuracy score directly\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true = y_test, y_pred = rfc_pred)\n",
    "print(round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15\n",
    "### What is the accuracy on the test set using the xgboost classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9351    0.9101    0.9224       712\n",
      "    unstable     0.9510    0.9651    0.9580      1288\n",
      "\n",
      "    accuracy                         0.9455      2000\n",
      "   macro avg     0.9430    0.9376    0.9402      2000\n",
      "weighted avg     0.9453    0.9455    0.9453      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state=1)\n",
    "xgb.fit(normalised_train_df, y_train)\n",
    "xgb_pred = xgb.predict(normalised_test_df)\n",
    "\n",
    "\n",
    "# for the classificaton report\n",
    "print(classification_report(y_test, xgb_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true = y_test, y_pred = xgb_pred)\n",
    "print(round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16\n",
    "### What is the accuracy on the test set using the LGBM classifier? In 4 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing lightgbm classifier\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier(random_state=1)\n",
    "lgbm.fit(normalised_train_df, y_train)\n",
    "lgbm_pred = lgbm.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9297    0.8919    0.9104       712\n",
      "    unstable     0.9415    0.9627    0.9520      1288\n",
      "\n",
      "    accuracy                         0.9375      2000\n",
      "   macro avg     0.9356    0.9273    0.9312      2000\n",
      "weighted avg     0.9373    0.9375    0.9372      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lgbm_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true = y_test, y_pred = lgbm_pred)\n",
    "print(round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17\n",
    "### To improve the Extra Trees Classifier, you will use the following parameters (number of estimators, minimum number of samples, minimum number of samples for leaf node and the number of features to consider when looking for the best split) for the hyperparameter grid needed to run a Randomized Cross Validation Search (RandomizedSearchCV). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing extra tree classifier and then initializing it\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree = ExtraTreesClassifier(random_state =1)\n",
    "tree.fit(normalised_train_df, y_train)\n",
    "tree_pred = tree.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9410    0.8511    0.8938       712\n",
      "    unstable     0.9218    0.9705    0.9455      1288\n",
      "\n",
      "    accuracy                         0.9280      2000\n",
      "   macro avg     0.9314    0.9108    0.9197      2000\n",
      "weighted avg     0.9287    0.9280    0.9271      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true = y_test, y_pred = tree_pred)\n",
    "print(round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "clf = RandomizedSearchCV(tree, hyperparameter_grid, random_state=1)\n",
    "check = clf.fit(normalised_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the best hyperparameters from the randomized search CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1000, 2, 8, None])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.best_params_.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18\n",
    "### Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "#Training a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV\n",
    "\n",
    "tree_hype = ExtraTreesClassifier(n_jobs = -1, verbose = 1,\n",
    "                                  n_estimators=1000, min_samples_split=2, \n",
    "                                 min_samples_leaf=8, max_features=None, random_state=1)\n",
    "tree_hype.fit(normalised_train_df, y_train)\n",
    "tree_hype_pred = tree_hype.predict(normalised_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9211    0.8694    0.8945       712\n",
      "    unstable     0.9300    0.9589    0.9442      1288\n",
      "\n",
      "    accuracy                         0.9270      2000\n",
      "   macro avg     0.9256    0.9141    0.9193      2000\n",
      "weighted avg     0.9268    0.9270    0.9265      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tree_hype_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true = y_test, y_pred = tree_hype_pred)\n",
    "print(round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The accuracy of the new optimal model is lower(0.927) than the initial ExtraTreesClassifier model with no hyperparameter tuning(0.928)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 20\n",
    "### Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13723975, 0.1405075 , 0.13468029, 0.13541676, 0.00368342,\n",
       "       0.00533686, 0.00542927, 0.00496249, 0.10256244, 0.10757765,\n",
       "       0.11306268, 0.10954089])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_hype.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = tree.feature_importances_\n",
    "df = pd.DataFrame(importance, index = normalised_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.039507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>0.040371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>0.040579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>0.040706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.089783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.093676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.094019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>0.096883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>0.113169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>0.115466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>0.117397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.118445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "p1    0.039507\n",
       "p2    0.040371\n",
       "p4    0.040579\n",
       "p3    0.040706\n",
       "g1    0.089783\n",
       "g2    0.093676\n",
       "g4    0.094019\n",
       "g3    0.096883\n",
       "tau3  0.113169\n",
       "tau4  0.115466\n",
       "tau1  0.117397\n",
       "tau2  0.118445"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The least important feature is p1\n",
    "### The most important feature is tau2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
